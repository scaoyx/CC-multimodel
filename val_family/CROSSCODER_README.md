# Crosscoder Family Specificity Analysis

This directory contains scripts to compute family specificity for protein embeddings extracted from a crosscoder model.

## Overview

These scripts adapt the InterPro family specificity analysis to work with crosscoder embeddings:

1. **crosscoder_compute_family_specificity.py** - Core analysis functions
2. **crosscoder_run_compute_family_specificity.py** - CLI interface

## Data Requirements

### Input Files

1. **Embeddings file** (`.pt` format): 
   - Generated by `extract_protein_embeddings.py`
   - Contains:
     - `embeddings`: Tensor of shape `[n_proteins, hidden_dim]`
     - `metadata`: Dict with `labels` and `sequences`
     - `processing_info`: Metadata about how embeddings were created

2. **TSV file** with protein annotations:
   - Must contain columns:
     - `Sequence`: Protein amino acid sequence
     - `Protein families`: Semicolon-separated list of family names
   - Example: `Correct_length_50k_random_swissprot.tsv`

## How It Works

For each dimension in the crosscoder embeddings:

1. Identifies the protein with the highest activation
2. For each protein family of that protein:
   - Creates a binary classification task (in family vs. not in family)
   - Optimizes a threshold to maximize F1 score on training data
   - Evaluates performance on test data
3. Reports metrics: F1, precision, recall, accuracy, ROC AUC

This identifies which embedding dimensions are specific to which protein families.

## Usage

### Basic Usage

```bash
python crosscoder_run_compute_family_specificity.py \
    --tsv-path Correct_length_50k_random_swissprot.tsv \
    --embeddings-path Meanpooled_5k_Comp_13modal.pt \
    --output-csv family_specific_features.csv
```

### All Options

```bash
python crosscoder_run_compute_family_specificity.py \
    --tsv-path <path_to_tsv> \
    --embeddings-path <path_to_embeddings.pt> \
    --class-list-col "Protein_families" \
    --output-csv results.csv \
    --output-parquet results.parquet
```

### Options

- `--tsv-path` (required): Path to TSV file with sequence and family annotations
- `--embeddings-path` (required): Path to `.pt` embeddings file
- `--class-list-col`: Column name for protein families (default: "Protein_families")
- `--output-csv`: Output CSV file path (default: "family_specific_features.csv")
- `--output-parquet`: Optional parquet output (requires pyarrow)

## Output Format

The output CSV/Parquet contains one row per dimension-family pair with columns:

- `dim`: Embedding dimension index
- `class`: Protein family name
- `threshold`: Optimal activation threshold for classification
- `accuracy`: Classification accuracy on test set
- `precision`: Precision on test set
- `recall`: Recall on test set
- `f1`: F1 score on test set
- `roc_auc`: ROC AUC score on test set
- `n_data_points`: Number of proteins in this family

## Example Output

```
dim,class,threshold,accuracy,precision,recall,f1,roc_auc,n_data_points
0,Kinase,0.7,0.95,0.92,0.88,0.90,0.94,150
0,Transferase,0.6,0.88,0.85,0.80,0.82,0.87,200
5,DNA-binding,0.8,0.93,0.90,0.89,0.89,0.92,175
...
```

## Dependencies

```bash
pip install pandas numpy torch scikit-learn tqdm click
# Optional for parquet support:
pip install pyarrow
```

## Differences from Original InterPro Scripts

1. **Input format**: Uses `.pt` files instead of `.npy` files
2. **Data loading**: Reads TSV instead of Parquet, uses pandas instead of polars
3. **Column name**: Uses "Protein families" instead of "InterPro"
4. **Metadata matching**: Matches embeddings with TSV data via sequences
5. **Transposition**: Transposes embeddings from `[n_proteins, hidden_dim]` to `[hidden_dim, n_proteins]`

## Troubleshooting

**No results generated:**
- Check that TSV has both 'Sequence' and 'Protein families' columns
- Verify embeddings file was created with `extract_protein_embeddings.py`
- Ensure sequences in embeddings match sequences in TSV

**Too few results:**
- Check that proteins have family annotations (non-empty 'Protein families')
- Verify there are enough examples per family (minimum 5 positive and 5 negative)

**Memory issues:**
- The script loads all embeddings into memory
- For very large datasets, consider processing in batches

## Example Workflow

1. Extract embeddings from crosscoder:
```bash
python extract_protein_embeddings.py \
    --tsv_file Correct_length_50k_random_swissprot.tsv \
    --checkpoint_path path/to/model.ckpt \
    --esm_model esm2_t6_8M_UR50D \
    --output_file Meanpooled_5k_Comp_13modal.pt
```

2. Compute family specificity:
```bash
python crosscoder_run_compute_family_specificity.py \
    --tsv-path Correct_length_50k_random_swissprot.tsv \
    --embeddings-path Meanpooled_5k_Comp_13modal.pt \
    --output-csv family_specific_features.csv
```

3. Analyze results:
```python
import pandas as pd
df = pd.read_csv('family_specific_features.csv')

# Find top families
print(df.groupby('class')['f1'].mean().sort_values(ascending=False).head(10))

# Find best dimensions
print(df.groupby('dim')['f1'].max().sort_values(ascending=False).head(10))
```
